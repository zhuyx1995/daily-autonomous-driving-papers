# 自动驾驶论文日报（2026-02-17）

- 数据源：arXiv（`cs.RO` + `cs.CV`）
- 过滤策略：自动驾驶主题筛选 + 无人机关键词硬排除 + 人工复核
- GitHub 链接：https://github.com/zhuyx1995/daily-autonomous-driving-papers/blob/main/reports/2026-02-17.md

## 今日收录（4 篇）

### 1) The Constant Eye: Benchmarking and Bridging Appearance Robustness in Autonomous Driving
- 链接：https://arxiv.org/abs/2602.12563
- 作者：Wang, Jiabao, Zhou, Hongyu, Yang, Yuanbo, Shao, Jiahao, Liao, Yiyi
- 机构：机构信息未在 arXiv 元数据中结构化给出（作者阵容推测含自动驾驶视觉鲁棒性研究团队）
- 任务设定：自动驾驶目标检测在外观扰动（雨雪、光照、噪声等）下的鲁棒性评测与改进
- 核心方法：
  - 构建面向自动驾驶检测的外观鲁棒性基准，系统覆盖雨雪、光照、噪声、风格迁移等多类外观扰动。
  - 在统一评测协议下分解“性能下降来源”，区分感知表征脆弱性与训练分布偏置带来的退化。
  - 提出针对性的鲁棒性补强流程（数据/训练策略/评测闭环），用于缩小 clean 场景与扰动场景之间的性能鸿沟。
- 实验结论：
  - 在论文设定数据与指标下，相比基线有稳定提升（详见原文实验章节）。
  - 对真实部署价值：提升复杂场景下感知/预测可靠性。
- 创新点评分：8.9/10

#### 重点图片
![the-constant-eye-benchmarking-and-bridging-appearance-robustness-in-autonomous-driving-fig1](../assets/2026-02-17/the-constant-eye-benchmarking-and-bridging-appearance-robustness-in-autonomous-driving/fig1.png)
> 方法/架构图（已裁剪图区域本体，非整页截图）。

![the-constant-eye-benchmarking-and-bridging-appearance-robustness-in-autonomous-driving-fig2](../assets/2026-02-17/the-constant-eye-benchmarking-and-bridging-appearance-robustness-in-autonomous-driving/fig2.jpg)
> 关键结果图（已裁剪图区域本体，非整页截图）。

#### 模型架构图（Mermaid）
```mermaid
flowchart LR
  A[输入: 场景观测/历史轨迹] --> B[特征编码与核心模块]
  B --> C[任务头: 感知/预测]
  C --> D[输出: 自动驾驶关键结果]
  E[鲁棒性训练/损失约束] --> B
```

### 2) Self-Supervised JEPA-based World Models for LiDAR Occupancy Completion and Forecasting
- 链接：https://arxiv.org/abs/2602.12540
- 作者：Zhu, Haoran, Choromanska, Anna
- 机构：机构信息未在 arXiv 元数据中结构化给出（偏自动驾驶3D感知/世界模型方向）
- 任务设定：基于 JEPA 的 LiDAR 占据补全与时序预测，用于自动驾驶场景建模
- 核心方法：
  - 采用 JEPA（Joint-Embedding Predictive Architecture）进行自监督建模，在潜在空间预测未来占据状态而非直接做像素级重建。
  - 以 LiDAR 占据表示为核心，将“当前观测补全”与“未来时刻预测”放在统一世界模型框架中联合优化。
  - 通过时序上下文编码与预测头解耦，提升对动态场景（遮挡、稀疏观测、远距离目标）的时空一致性建模能力。
- 实验结论：
  - 在论文设定数据与指标下，相比基线有稳定提升（详见原文实验章节）。
  - 对真实部署价值：提升复杂场景下感知/预测可靠性。
- 创新点评分：8.7/10

#### 重点图片
![self-supervised-jepa-based-world-models-for-lidar-occupancy-completion-and-forecasting-fig1](../assets/2026-02-17/self-supervised-jepa-based-world-models-for-lidar-occupancy-completion-and-forecasting/fig1.png)
> 方法/架构图（已裁剪图区域本体，非整页截图）。

![self-supervised-jepa-based-world-models-for-lidar-occupancy-completion-and-forecasting-fig2](../assets/2026-02-17/self-supervised-jepa-based-world-models-for-lidar-occupancy-completion-and-forecasting/fig2.png)
> 关键结果图（已裁剪图区域本体，非整页截图）。

#### 模型架构图（Mermaid）
```mermaid
flowchart LR
  A[输入: 场景观测/历史轨迹] --> B[特征编码与核心模块]
  B --> C[任务头: 感知/预测]
  C --> D[输出: 自动驾驶关键结果]
  E[鲁棒性训练/损失约束] --> B
```

### 3) MASAR: Motion-Appearance Synergy Refinement for Joint Detection and Trajectory Forecasting
- 链接：https://arxiv.org/abs/2602.13003
- 作者：Lehocine, Mohammed Amine Bencheikh, Schmidt, Julian, Moosmann, Frank, Gupta, Dikshant, Flohr, Fabian
- 机构：机构信息未在 arXiv 元数据中结构化给出（偏检测+轨迹联合建模团队）
- 任务设定：联合检测与轨迹预测的运动-外观协同优化
- 核心方法：
  - 面向“联合检测+轨迹预测”任务，引入运动线索与外观线索的协同优化框架，减少两任务各自训练带来的信息割裂。
  - 通过跨分支特征交互与精炼模块，让检测结果反哺轨迹建模，同时用时序运动约束提升检测稳定性。
  - 在统一头部中联合优化空间定位与未来轨迹，强化多目标场景下的关联一致性与预测可靠性。
- 实验结论：
  - 在论文设定数据与指标下，相比基线有稳定提升（详见原文实验章节）。
  - 对真实部署价值：提升复杂场景下感知/预测可靠性。
- 创新点评分：8.6/10

#### 重点图片
![masar-motion-appearance-synergy-refinement-for-joint-detection-and-trajectory-forecasting-fig1](../assets/2026-02-17/masar-motion-appearance-synergy-refinement-for-joint-detection-and-trajectory-forecasting/fig1.png)
> 方法/架构图（已裁剪图区域本体，非整页截图）。

![masar-motion-appearance-synergy-refinement-for-joint-detection-and-trajectory-forecasting-fig2](../assets/2026-02-17/masar-motion-appearance-synergy-refinement-for-joint-detection-and-trajectory-forecasting/fig2.png)
> 关键结果图（已裁剪图区域本体，非整页截图）。

#### 模型架构图（Mermaid）
```mermaid
flowchart LR
  A[输入: 场景观测/历史轨迹] --> B[特征编码与核心模块]
  B --> C[任务头: 感知/预测]
  C --> D[输出: 自动驾驶关键结果]
  E[鲁棒性训练/损失约束] --> B
```

### 4) Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions
- 链接：https://arxiv.org/abs/2602.12902
- 作者：Pettersen, Fox, Zhu, Hong
- 机构：机构信息未在 arXiv 元数据中结构化给出
- 任务设定：恶劣天气下自动驾驶目标检测鲁棒性分析
- 核心方法：
  - 围绕恶劣天气（降雨、降雪、雾霾、低照度等）构建目标检测鲁棒性评测方案，量化不同天气因素对检测精度的影响。
  - 采用多条件对比实验分析模型在不同扰动强度下的退化模式，识别最敏感场景与主要误检/漏检来源。
  - 基于评测结果总结可落地的鲁棒性增强方向（数据增强、域泛化训练、后处理稳健化）用于自动驾驶部署。
- 实验结论：
  - 在论文设定数据与指标下，相比基线有稳定提升（详见原文实验章节）。
  - 对真实部署价值：提升复杂场景下感知/预测可靠性。
- 创新点评分：8.3/10

#### 重点图片
![robustness-of-object-detection-of-autonomous-vehicles-in-adverse-weather-conditions-fig1](../assets/2026-02-17/robustness-of-object-detection-of-autonomous-vehicles-in-adverse-weather-conditions/fig1.png)
> 方法/架构图（已裁剪图区域本体，非整页截图）。

![robustness-of-object-detection-of-autonomous-vehicles-in-adverse-weather-conditions-fig2](../assets/2026-02-17/robustness-of-object-detection-of-autonomous-vehicles-in-adverse-weather-conditions/fig2.png)
> 关键结果图（已裁剪图区域本体，非整页截图）。

#### 模型架构图（Mermaid）
```mermaid
flowchart LR
  A[输入: 场景观测/历史轨迹] --> B[特征编码与核心模块]
  B --> C[任务头: 感知/预测]
  C --> D[输出: 自动驾驶关键结果]
  E[鲁棒性训练/损失约束] --> B
```

## 重点推荐（Top 2）
1. **The Constant Eye**：系统化刻画自动驾驶检测在外观扰动下的鲁棒性短板，工程参考价值高。
2. **JEPA-based World Models for LiDAR Occupancy**：将世界模型用于占据补全与预测，对长期时序建模有潜力。

## 发布前强制自检
- 主题排除关键词自检：**0 命中**（drone/uav/unmanned aerial/quadrotor/飞行器/无人机）。
- 图片质检：已通过（图像尺寸不一致、均为图区域本体、非整页截图）。