# 每日自动驾驶论文报告 - 2026-02-11

**日期**: 2026-02-11  
**来源**: arXiv cs.RO + cs.CV  
**筛选关键词**: autonomous driving, self-driving, BEV, occupancy, HD map, trajectory prediction, path planning, perception, end-to-end driving, ADAS, CAV

---

## 今日论文概览

今日从arXiv cs.RO和cs.CV分类中筛选出 **5篇** 与自动驾驶相关的论文。

| 序号 | 论文标题 | 作者 | 领域 | 重要性 | 突破性 |
|------|----------|------|------|--------|--------|
| 1 | A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging | Bharathkumar Hegde, Melanie Bouroche | CAV/多智能体 | ⭐⭐⭐⭐ | 中 |
| 2 | Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation | Gonzalez-Garcia et al. | 运动规划 | ⭐⭐⭐⭐ | 中 |
| 3 | AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild | Sun et al. | 端到端导航 | ⭐⭐⭐⭐⭐ | 高 |
| 4 | Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving | Varghese et al. | 语义分割 | ⭐⭐⭐⭐ | 中 |
| 5 | Perception with Guarantees: Certified Pose Estimation via Reachability Analysis | Ladner et al. | 感知/定位 | ⭐⭐⭐⭐⭐ | 高 |

---

## 论文详细分析

### 1. A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging

**论文信息**
- **arXiv ID**: 2602.10007
- **链接**: https://arxiv.org/abs/2602.10007
- **作者**: Bharathkumar Hegde, Melanie Bouroche
- **会议**: IEEE IV 2026 (Accepted)
- **代码**: https://github.com/hkbharath/MARL-MASS

**摘要**
密集交通中的换道是智能网联自动驾驶汽车(CAV)面临的重大挑战。现有的换道控制器要么只确保安全，要么只协作提高交通效率，但没有同时考虑这两个相互冲突的目标。为此，作者提出了多智能体安全盾(MASS)，使用控制屏障函数(CBF)实现安全且协作的换道。MASS通过图结构交互拓扑捕获CAV间的多智能体交互，实现协作。此外，通过集成MASS确保安全，并定义定制奖励函数优先考虑效率改进，扩展了最先进的多智能体强化学习(MARL)换道控制器。

**核心方法**
1. **MASS框架**: 基于控制屏障函数的安全盾设计
2. **图交互拓扑**: 构建多智能体间的交互关系图
3. **MARL-MASS**: 结合MARL与MASS的安全高效换道控制器
4. **定制奖励函数**: 平衡安全性与交通效率

**实验结果**
- 在拥堵的匝道汇入场景中进行仿真评估
- MASS确保安全约束的严格满足
- 定制奖励函数提高了MARL策略训练的稳定性
- 有效平衡安全性与交通效率的权衡

**创新点**
- 首次将安全盾与协作换道结合
- 通过图结构建模多智能体交互
- 提出兼顾安全与效率的奖励函数设计

**评价**
- **重要性**: ⭐⭐⭐⭐ (4/5) - CAV协作与安全的关键问题
- **突破性**: 中 - 方法组合创新，但CBF应用较为成熟

---

### 2. Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation of Structured Environments

**论文信息**
- **arXiv ID**: 2602.09714
- **链接**: https://arxiv.org/abs/2602.09714
- **作者**: Alejandro Gonzalez-Garcia, Sebastiaan Wyns, Sonia De Santis, Jan Swevers, Wilm Decré
- **会议**: ICRA 2026 (Accepted)
- **代码**: 开源实现可用

**摘要**
本文提出了一套完整的框架，用于在高度复杂但结构化的环境中实现非完整约束自主移动机器人的快速运动规划。传统的基于网格的规划器难以扩展，而许多运动学可行规划器由于其搜索空间复杂性而带来显著的计算负担。为克服这些限制，该方法引入确定性自由空间分解，创建重叠矩形走廊的紧凑图。这种方法实现了搜索空间的显著缩减，同时不牺牲路径分辨率。框架通过寻找矩形序列并使用分析规划器生成接近时间最优、运动学可行的轨迹来进行在线运动规划。

**核心方法**
1. **矩形走廊表示**: 确定性自由空间分解
2. **紧凑图构建**: 重叠矩形走廊图
3. **分析规划器**: 生成运动学可行轨迹
4. **在线规划**: 序列矩形搜索 + 轨迹生成

**实验结果**
- 大规模仿真实验验证
- 物理机器人平台验证
- 计算效率高，适用于大规模导航
- 实现为开源软件

**创新点**
- 矩形走廊表示有效压缩搜索空间
- 保持路径分辨率的同时提高效率
- 分析轨迹生成确保运动学可行性

**评价**
- **重要性**: ⭐⭐⭐⭐ (4/5) - 运动规划是自动驾驶核心模块
- **突破性**: 中 - 表示方法创新，但属于渐进式改进

---

### 3. AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild

**论文信息**
- **arXiv ID**: 2602.09657
- **链接**: https://arxiv.org/abs/2602.09657
- **作者**: Xiaolou Sun, Wufei Si, Wenhui Ni, Yuntian Li, Dongming Wu, Fei Xie, Runwei Guan, He-Yang Xu, Henghui Ding, Yuan Wu, Yutao Yue, Yongming Huang, Hui Xiong
- **会议**: ICLR 2026 (Accepted)
- **数据集**: 构建了新型自主导航数据集

**摘要**
视觉语言导航(VLN)要求智能体通过解释语言指令和视觉观察来导航环境。当前的无人机VLN研究依赖于详细的预指定指令来引导无人机沿预定路线飞行。然而，真实世界户外探索通常发生在未知环境中，详细导航指令不可用。为此，作者提出AutoFly，一种端到端视觉语言动作(VLA)模型用于自主无人机导航。AutoFly结合了从RGB输入推导深度感知特征的伪深度编码器，以及渐进式两阶段训练策略，有效对齐视觉、深度和语言表示与动作策略。

**核心方法**
1. **伪深度编码器**: 从RGB输入提取深度感知特征
2. **VLA架构**: 端到端视觉-语言-动作模型
3. **渐进两阶段训练**: 对齐多模态表示
4. **自主导航数据集**: 从指令跟随转向自主行为建模

**实验结果**
- 相比最先进VLA基线成功率提高3.9%
- 在仿真和真实环境中表现一致
- 构建了强调连续避障、自主规划和识别工作流的新数据集

**创新点**
- 首次将VLA模型应用于户外无人机自主导航
- 伪深度编码器增强空间推理能力
- 从指令跟随到自主决策的范式转变
- 大规模真实世界数据整合

**评价**
- **重要性**: ⭐⭐⭐⭐⭐ (5/5) - 端到端自动驾驶的重要进展
- **突破性**: 高 - VLA在户外自主导航的开创性应用

---

### 4. Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving

**论文信息**
- **arXiv ID**: 2602.10052
- **链接**: https://arxiv.org/abs/2602.10052
- **作者**: Serin Varghese, Kevin Ross, Fabian Hueger, Kira Maag

**摘要**
深度神经网络，特别是基于Transformer的架构，在环境感知的语义分割方面取得了显著成功。然而，现有模型独立处理视频帧，未能利用时间一致性，而这可以显著提高动态场景中的准确性和稳定性。本文提出时空注意力(STA)机制，扩展Transformer注意力块以纳入多帧上下文，实现视频语义分割的鲁棒时间特征表示。该方法修改标准自注意力以处理时空特征序列，同时保持计算效率。

**核心方法**
1. **时空注意力(STA)**: 扩展Transformer处理多帧上下文
2. **自注意力修改**: 处理时空特征序列
3. **架构无关性**: 可应用于多种Transformer架构
4. **计算效率**: 对现有架构改动最小

**实验结果**
- Cityscapes和BDD100k数据集评估
- 时间一致性指标提升9.20个百分点
- mIoU相比单帧基线提升最多1.76个百分点
- 在轻量级和大规模模型上均有效

**创新点**
- 简单有效的时空注意力扩展
- 无需大幅修改现有架构
- 显著提升视频分割的时间一致性

**评价**
- **重要性**: ⭐⭐⭐⭐ (4/5) - 视频分割对自动驾驶感知很重要
- **突破性**: 中 - 方法简洁有效，但属于注意力机制的扩展应用

---

### 5. Perception with Guarantees: Certified Pose Estimation via Reachability Analysis

**论文信息**
- **arXiv ID**: 2602.10032
- **链接**: https://arxiv.org/abs/2602.10032
- **作者**: Tobias Ladner, Yasser Shoukry, Matthias Althoff
- **领域**: 计算机视觉与机器人学交叉

**摘要**
信息物理系统中的智能体越来越多地被委托执行安全关键任务。确保这些智能体的安全通常需要定位位姿以执行后续动作。位姿估计可以从激光雷达传感器、摄像头和GPS等外部服务的各种组合中获得。关键的是，在安全关键领域，粗略估计不足以正式确定安全性，即在最坏情况下也能保证安全，而且外部服务可能不可信。本文通过呈现仅来自相机图像和已知目标几何的3D认证位姿估计来解决这个问题。这是通过利用可达性分析和形式化神经网络验证的最新结果来形式化地约束位姿来实现的。

**核心方法**
1. **认证位姿估计**: 形式化方法保证估计边界
2. **可达性分析**: 约束位姿估计的不确定性
3. **神经网络形式化验证**: 确保最坏情况下的安全性
4. **单目相机 + 目标几何**: 不依赖外部服务

**实验结果**
- 合成和真实世界实验验证
- 高效准确地定位智能体
- 提供形式化安全保证
- 不依赖GPS等外部服务

**创新点**
- 将形式化方法引入位姿估计
- 提供可证明的安全保证
- 解决外部服务不可信问题
- 融合可达性分析与神经网络验证

**评价**
- **重要性**: ⭐⭐⭐⭐⭐ (5/5) - 安全关键应用中的形式化保证至关重要
- **突破性**: 高 - 形式化验证与感知的结合是前沿方向

---

## 总结

今日筛选的5篇论文涵盖了自动驾驶的多个关键领域：

1. **CAV协作与安全** (MARL-MASS): 多智能体强化学习与安全盾结合
2. **运动规划** (Rectangular Corridor): 高效的矩形走廊表示方法
3. **端到端导航** (AutoFly): 视觉语言动作模型在无人机导航的创新应用
4. **感知分割** (STA): 时空注意力提升视频语义分割一致性
5. **形式化安全** (Certified Pose): 可达性分析保证位姿估计安全性

**研究趋势观察**:
- 端到端学习(VLA模型)在自动驾驶中的应用日益广泛
- 形式化方法与深度学习的结合成为安全关键应用的重要方向
- 多模态融合(视觉+语言+深度)成为主流范式
- 协作式自动驾驶(CAV)研究持续深入

---

*报告生成时间: 2026-02-11*  
*数据来源: arXiv.org*
